{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from learn_process import init_data\n",
    "from visualization.visualize_data import plot_sample\n",
    "from networks.unet_leiterrl import weights_init, TurbNetG, UNet\n",
    "from networks.dummy_network import DummyNet\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.nn import MSELoss\n",
    "import torch.nn.functional as F\n",
    "from solver import Solver\n",
    "\n",
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # init data\n",
    "datasets_2D, dataloaders_2D = init_data(dataset_name=\"perm_pressure1D_10dp\", #\"OLD_bash_file_and_script_structure/groundtruth_hps_no_hps/groundtruth_hps_overfit_10\", \n",
    "        reduce_to_2D=True, reduce_to_2D_xy=True,\n",
    "        inputs=\"pk\", labels=\"t\") #, batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of model and training\n",
    "loss_fn = MSELoss()\n",
    "n_epochs = 1 #00 #60000\n",
    "\n",
    "unet_model = UNet(in_channels=3, out_channels=1).float()\n",
    "# TODO too many in channels for unet?\n",
    "# fc_model = DummyNet().float()\n",
    "# model.to(device)\n",
    "\n",
    "name_folder=\"try_unstructured_grid\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=5e-4 #0.0005 #0.0004\n",
    "\n",
    "datasets_2D, dataloaders_2D = init_data(dataset_name=\"perm_pressure1D_10dp\", #\"OLD_bash_file_and_script_structure/groundtruth_hps_no_hps/groundtruth_hps_overfit_10\", \n",
    "        reduce_to_2D=True, reduce_to_2D_xy=True,\n",
    "        inputs=\"pk\", labels=\"t\") #, batch_size=3)\n",
    "\n",
    "# # train model\n",
    "# _, writer = train_model(unet_model, dataloaders_2D, loss_fn, n_epochs, learning_rate, name_folder=name_folder)\n",
    "# solver = Solver(unet_model, dataloaders_2D[\"train\"], dataloaders_2D[\"val\"], \n",
    "#                 learning_rate=learning_rate, loss_func=loss_fn)\n",
    "solver.train(n_epochs=n_epochs, name_folder=name_folder)\n",
    "\n",
    "error, error_mean = plot_sample(unet_model, dataloaders_2D[\"train\"], name_folder, plot_name=\"plot_learned_test_sample\")\n",
    "# print(\"Mean: \", error_mean, \"Max: \", max(error).item(), \"Min: \", error.min().item()) # not working with lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error, error_mean = plot_sample(unet_model, dataloaders_2D[\"train\"], name_folder, plot_name=\"plot_learned_test_sample\")\n",
    "print(\"Mean: \", error_mean, \"Max: \", error.max().item(), \"Min: \", error.min().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_w_current_settings(dataset_name:str=\"groundtruth_hps_no_hps/3datapoints_1D\", destination_folder:str=\"unet_3datapoints_learn1_Fabians_values\", n_epochs:int=1, reduce_to_2D:bool=True, reduce_to_2D_xy:bool=True):\n",
    "    ## init data\n",
    "    datasets_2D, dataloaders_2D = init_data(dataset_name=dataset_name, #\"OLD_bash_file_and_script_structure/groundtruth_hps_no_hps/groundtruth_hps_overfit_10\", \n",
    "            reduce_to_2D=reduce_to_2D, reduce_to_2D_xy=reduce_to_2D_xy,\n",
    "            inputs=\"xyzt\", labels=\"t\") #, batch_size=3)\n",
    "\n",
    "    ##settings (training)\n",
    "    # parameters of model and training\n",
    "    loss_fn = MSELoss()\n",
    "    n_epochs = n_epochs #1000 #60000\n",
    "    lr=0.0004 #0.0004\n",
    "\n",
    "    #model = TurbNetG(channelExponent=4, in_channels=4, out_channels=2)\n",
    "    unet_model = UNet(in_channels=5, out_channels=1).float()\n",
    "    # TODO too many in channels for unet?\n",
    "    fc_model = DummyNet().float()\n",
    "    # model.to(device)\n",
    "\n",
    "    # name_folder=\"try_dummy_overfit10_try_reduce2d_xy\"\n",
    "\n",
    "    ## train model\n",
    "    _, writer = train_model(unet_model, dataloaders_2D, loss_fn, n_epochs, lr, name_folder=name_folder)\n",
    "\n",
    "    ## visualize\n",
    "    writer, error, error_mean = plot_ample(unet_model, dataloaders_2D, name_folder, plot_name=\"plot_learned_test_sample\")\n",
    "    print(\"Mean: \", error_mean, \"Max: \", error.max().item(), \"Min: \", error.min().item())\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_w_current_settings(dataset_name=\"groundtruth_hps_no_hps/3datapoints_1D\", destination_folder=\"unet_3datapoints_learn1_Fabians_values\", n_epochs=30)\n",
    "run_w_current_settings() #dataset_name=\"groundtruth_hps_no_hps/2datapoints\", destination_folder=\"unet_3datapoints_learn1_reasonable_values\", n_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "datasets, dataloaders = init_data(dataset_name=\"groundtruth_hps_no_hps/3datapoints_1D\", \n",
    "            reduce_to_2D=False, reduce_to_2D_xy=False,\n",
    "            inputs=\"xyzt\", labels=\"t\") #, batch_size=3)\n",
    "ids = datasets[\"train\"][0].inputs[\"Material_ID\"].value\n",
    "# print(ids)\n",
    "print(ids.min(), ids.max())\n",
    "max_id = ids.max()\n",
    "loc_hp = np.where(ids == max_id)\n",
    "number_cells = [20, 150, 16]\n",
    "int(9+1 + 23*number_cells[0] + 9*number_cells[0]*number_cells[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO NEXT FIND THE ID OF THE HEATPUMP AND COMPARE TO UNSTRUCTURED GRID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
