{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cut boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"dataset_2d_small_100dp inputs_gksi\"\n",
    "with open(\"paths.yaml\", \"r\") as paths:\n",
    "    paths = yaml.safe_load(paths)\n",
    "    prepared1_dir = Path(paths[\"datasets_prepared_dir\"]) / dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_boxes = 4\n",
    "# prepared_dir_1stlevel = Path(paths[\"datasets_prepared_dir\"]) / f\"{dataset_name} cut_{number_boxes}pieces\"\n",
    "# prepared_dir_1stlevel.mkdir(parents=True, exist_ok=True)\n",
    "# (prepared_dir_1stlevel / \"Inputs\").mkdir(parents=True, exist_ok=True)\n",
    "# (prepared_dir_1stlevel / \"Labels\").mkdir(parents=True, exist_ok=True)\n",
    "# (prepared_dir_1stlevel / \"LaterBoxes\").mkdir(parents=True, exist_ok=True)\n",
    "# shutil.copy(prepared1_dir / \"info.yaml\", prepared_dir_1stlevel / \"info.yaml\")\n",
    "\n",
    "# for datapoint in zip((prepared1_dir / \"Inputs\").iterdir(), (prepared1_dir / \"Labels\").iterdir()):\n",
    "#     input = torch.load(datapoint[0])\n",
    "#     label = torch.load(datapoint[1])\n",
    "#     name = datapoint[0].stem\n",
    "#     # input = torch.load(prepared1_dir / \"Inputs\" / \"RUN_1.pt\")\n",
    "#     # label = torch.load(prepared1_dir / \"Labels\" / \"RUN_1.pt\")\n",
    "\n",
    "#     input_boxes = []\n",
    "#     label_boxes = []\n",
    "#     for i in range(number_boxes):\n",
    "#         len_box = input.shape[1] // number_boxes\n",
    "#         input_boxes.append(input[:, i * len_box : (i + 1) * len_box, :])\n",
    "#         label_boxes.append(label[:, i * len_box : (i + 1) * len_box, :])\n",
    "\n",
    "#     torch.save(input_boxes[0], prepared_dir_1stlevel / \"Inputs\" / f\"{name}.pt\",)\n",
    "#     torch.save(label_boxes[0], prepared_dir_1stlevel / \"Labels\" / f\"{name}.pt\",)\n",
    "\n",
    "#     for i in range(1, number_boxes):\n",
    "#         torch.save(label_boxes[i], prepared_dir_1stlevel / \"LaterBoxes\" / f\"{name}_box_{i}.pt\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO run main.py as only_interfer = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move outputs of first level and second level of boxes to new folder for next training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box_nr_label = 1\n",
    "# trained_level1_dir = prepared_dir_1stlevel.parent / f\"{dataset_name} cut_{number_boxes}pieces box{box_nr_label-1}to{box_nr_label}\"\n",
    "# trained_level1_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# info = yaml.safe_load(open(prepared_dir_1stlevel / \"info.yaml\", \"r\"))\n",
    "# info[\"Inputs\"] = deepcopy(info[\"Labels\"])\n",
    "# yaml.safe_dump(info, open(trained_level1_dir / \"info.yaml\", \"w\"))\n",
    "# try:\n",
    "#     shutil.copytree(prepared_dir_1stlevel / \"Outputs\", trained_level1_dir/ \"Inputs\")\n",
    "# except:\n",
    "#     pass\n",
    "# (trained_level1_dir / \"Labels\").mkdir(parents=True, exist_ok=True)\n",
    "# for file in (prepared_dir_1stlevel / \"LaterBoxes\").iterdir():\n",
    "#     box_name = f\"_box_{box_nr_label}\"\n",
    "#     if box_name in file.name:\n",
    "#         shutil.copy(file, trained_level1_dir / \"Labels\" / file.name.replace(box_name, \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"paths.yaml\", \"r\") as paths:\n",
    "#     paths = yaml.safe_load(paths)\n",
    "#     dataset_prep_dir = Path(paths[\"datasets_prepared_dir\"])\n",
    "\n",
    "# print(torch.load(dataset_prep_dir / f\"dataset_2d_small_100dp inputs_gksi cut_4pieces box0to1/Inputs/RUN_0.pt\").shape)\n",
    "# print(torch.load(dataset_prep_dir / f\"dataset_2d_small_100dp inputs_gksi cut_4pieces box0to1/Labels/RUN_0.pt\").shape)\n",
    "\n",
    "# idx = 50\n",
    "# plt.subplots(1, 2)\n",
    "# plt.subplot(1, 2, 1)\n",
    "# test_pic = torch.load(dataset_prep_dir / f\"dataset_2d_small_100dp inputs_gksi cut_4pieces box0to1/Inputs/RUN_{idx}.pt\").cpu().detach().numpy().T\n",
    "# plt.imshow(test_pic)\n",
    "# plt.colorbar()\n",
    "# plt.subplot(1, 2, 2)\n",
    "# test_pic = torch.load(dataset_prep_dir / f\"dataset_2d_small_100dp inputs_gksi cut_4pieces box0to1/Labels/RUN_{idx}.pt\").cpu().detach().numpy()[0].T\n",
    "# plt.imshow(test_pic)\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box_nr_label = 2\n",
    "# trained_level1_dir = prepared_dir_1stlevel.parent / f\"{dataset_name} cut_{number_boxes}pieces box{box_nr_label-2}to{box_nr_label-1}\"\n",
    "# trained_level2_dir = prepared_dir_1stlevel.parent / f\"{dataset_name} cut_{number_boxes}pieces box{box_nr_label-1}to{box_nr_label}\"\n",
    "# trained_level2_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# info = yaml.safe_load(open(prepared_dir_1stlevel / \"info.yaml\", \"r\"))\n",
    "# info[\"Inputs\"] = deepcopy(info[\"Labels\"])\n",
    "# yaml.safe_dump(info, open(trained_level2_dir / \"info.yaml\", \"w\"))\n",
    "# try:\n",
    "#     shutil.copytree(trained_level1_dir / \"Outputs\", trained_level2_dir/ \"Inputs\")\n",
    "# except:\n",
    "#     pass\n",
    "# (trained_level2_dir / \"Labels\").mkdir(parents=True, exist_ok=True)\n",
    "# for file in (prepared_dir_1stlevel / \"LaterBoxes\").iterdir():\n",
    "#     box_name = f\"_box_{box_nr_label}\"\n",
    "#     if box_name in file.name:\n",
    "#         shutil.copy(file, trained_level2_dir / \"Labels\" / file.name.replace(box_name, \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"paths.yaml\", \"r\") as paths:\n",
    "#     paths = yaml.safe_load(paths)\n",
    "#     dataset_prep_dir = Path(paths[\"datasets_prepared_dir\"])\n",
    "\n",
    "# print(torch.load(dataset_prep_dir / f\"dataset_2d_small_100dp inputs_gksi cut_4pieces box1to2/Inputs/RUN_0.pt\").shape)\n",
    "# print(torch.load(dataset_prep_dir / f\"dataset_2d_small_100dp inputs_gksi cut_4pieces box1to2/Labels/RUN_0.pt\").shape)\n",
    "\n",
    "# idx = 50\n",
    "# plt.subplots(1, 2)\n",
    "# plt.subplot(1, 2, 1)\n",
    "# test_pic = torch.load(dataset_prep_dir / f\"dataset_2d_small_100dp inputs_gksi cut_4pieces box1to2/Inputs/RUN_{idx}.pt\").cpu().detach().numpy().T\n",
    "# plt.imshow(test_pic)\n",
    "# plt.colorbar()\n",
    "# plt.subplot(1, 2, 2)\n",
    "# test_pic = torch.load(dataset_prep_dir / f\"dataset_2d_small_100dp inputs_gksi cut_4pieces box1to2/Labels/RUN_{idx}.pt\").cpu().detach().numpy()[0].T\n",
    "# plt.imshow(test_pic)\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box_nr_label = 3\n",
    "# trained_level1_dir = prepared_dir_1stlevel.parent / f\"{dataset_name} cut_{number_boxes}pieces box{box_nr_label-2}to{box_nr_label-1}\"\n",
    "# trained_level2_dir = prepared_dir_1stlevel.parent / f\"{dataset_name} cut_{number_boxes}pieces box{box_nr_label-1}to{box_nr_label}\"\n",
    "# trained_level2_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# info = yaml.safe_load(open(prepared_dir_1stlevel / \"info.yaml\", \"r\"))\n",
    "# info[\"Inputs\"] = deepcopy(info[\"Labels\"])\n",
    "# yaml.safe_dump(info, open(trained_level2_dir / \"info.yaml\", \"w\"))\n",
    "# try:\n",
    "#     shutil.copytree(trained_level1_dir / \"Outputs\", trained_level2_dir/ \"Inputs\")\n",
    "# except:\n",
    "#     pass\n",
    "# (trained_level2_dir / \"Labels\").mkdir(parents=True, exist_ok=True)\n",
    "# for file in (prepared_dir_1stlevel / \"LaterBoxes\").iterdir():\n",
    "#     box_name = f\"_box_{box_nr_label}\"\n",
    "#     if box_name in file.name:\n",
    "#         shutil.copy(file, trained_level2_dir / \"Labels\" / file.name.replace(box_name, \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test pipeline of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# other dataset: all gt of former box + label of this box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_boxes = 4\n",
    "# prepared_dir_1stlevel = Path(paths[\"datasets_prepared_dir\"]) / f\"{dataset_name} cut_{number_boxes}pieces\"\n",
    "# prepared_dir_2ndlevel = Path(paths[\"datasets_prepared_dir\"]) / f\"{dataset_name} cut_{number_boxes}pieces 2nd_level\"\n",
    "# prepared_dir_2ndlevel.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# (prepared_dir_2ndlevel / \"Inputs\").mkdir(parents=True, exist_ok=True)\n",
    "# (prepared_dir_2ndlevel / \"Labels\").mkdir(parents=True, exist_ok=True)\n",
    "# shutil.copy(prepared_dir_1stlevel / \"info.yaml\", prepared_dir_2ndlevel / \"info.yaml\")\n",
    "\n",
    "# for datapoint in zip((prepared_dir_1stlevel / \"Labels\").iterdir(), (prepared1_dir / \"LaterBoxes\").iterdir()):\n",
    "#     input = torch.load(datapoint[0])\n",
    "#     label = torch.load(datapoint[1])\n",
    "#     name = datapoint[0].stem\n",
    "#     # input = torch.load(prepared1_dir / \"Inputs\" / \"RUN_1.pt\")\n",
    "#     # label = torch.load(prepared1_dir / \"Labels\" / \"RUN_1.pt\")\n",
    "\n",
    "#     input_boxes = []\n",
    "#     label_boxes = []\n",
    "#     for i in range(number_boxes):\n",
    "#         len_box = input.shape[1] // number_boxes\n",
    "#         input_boxes.append(input[:, i * len_box : (i + 1) * len_box, :])\n",
    "#         label_boxes.append(label[:, i * len_box : (i + 1) * len_box, :])\n",
    "\n",
    "#     torch.save(input_boxes[0], prepared_dir_1stlevel / \"Inputs\" / f\"{name}.pt\",)\n",
    "#     torch.save(label_boxes[0], prepared_dir_1stlevel / \"Labels\" / f\"{name}.pt\",)\n",
    "\n",
    "#     for i in range(1, number_boxes):\n",
    "#         torch.save(label_boxes[i], prepared_dir_1stlevel / \"LaterBoxes\" / f\"{name}_box_{i}.pt\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_boxes = 4\n",
    "prepared_pieces_dir = Path(paths[\"datasets_prepared_dir\"]) / f\"{dataset_name} cut_{number_boxes}pieces separate_boxes\"\n",
    "prepared_pieces_dir.mkdir(parents=True, exist_ok=True)\n",
    "for box in range(number_boxes):\n",
    "    (prepared_pieces_dir / f\"Inputs Box {box}\").mkdir(parents=True, exist_ok=True)\n",
    "    (prepared_pieces_dir / f\"Label Box {box}\").mkdir(parents=True, exist_ok=True)\n",
    "shutil.copy(prepared1_dir / \"info.yaml\", prepared_pieces_dir / \"info.yaml\")\n",
    "\n",
    "for datapoint in zip((prepared1_dir / \"Inputs\").iterdir(), (prepared1_dir / \"Labels\").iterdir()):\n",
    "    input = torch.load(datapoint[0])\n",
    "    label = torch.load(datapoint[1])\n",
    "    name = datapoint[0].stem\n",
    "\n",
    "    input_boxes = []\n",
    "    label_boxes = []\n",
    "    for i in range(number_boxes):\n",
    "        len_box = input.shape[1] // number_boxes\n",
    "        input_boxes.append(input[:, i * len_box : (i + 1) * len_box, :])\n",
    "        label_boxes.append(label[:, i * len_box : (i + 1) * len_box, :])\n",
    "\n",
    "\n",
    "    for i in range(number_boxes):\n",
    "        torch.save(input_boxes[i], prepared_pieces_dir / f\"Inputs Box {i}\" / f\"{name}.pt\",)\n",
    "        torch.save(label_boxes[i], prepared_pieces_dir / f\"Label Box {i}\" / f\"{name}.pt\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare 1st level\n",
    "prepared_dir_1stlevel = Path(paths[\"datasets_prepared_dir\"]) / f\"{dataset_name} cut_{number_boxes}pieces separate_boxes 1st level\"\n",
    "prepared_dir_1stlevel.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "shutil.copy(prepared_pieces_dir / \"info.yaml\", prepared_dir_1stlevel / \"info.yaml\")\n",
    "shutil.copytree(prepared_pieces_dir / \"Inputs Box 0\", prepared_dir_1stlevel / \"Inputs\")\n",
    "shutil.copytree(prepared_pieces_dir / \"Label Box 0\", prepared_dir_1stlevel / \"Labels\")\n",
    "\n",
    "# prepare 2nd level\n",
    "prepared_dir_2ndlevel = Path(paths[\"datasets_prepared_dir\"]) / f\"{dataset_name} cut_{number_boxes}pieces separate_boxes 2nd level\"\n",
    "prepared_dir_2ndlevel.mkdir(parents=True, exist_ok=True)\n",
    "(prepared_dir_2ndlevel / \"Inputs\").mkdir(parents=True, exist_ok=True)\n",
    "(prepared_dir_2ndlevel / \"Labels\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "info = yaml.safe_load(open(prepared_dir_1stlevel / \"info.yaml\", \"r\"))\n",
    "info[\"Inputs\"] = deepcopy(info[\"Labels\"])\n",
    "yaml.safe_dump(info, open(prepared_dir_2ndlevel / \"info.yaml\", \"w\"))\n",
    "\n",
    "for box in range(number_boxes-1):\n",
    "    for file_in_temp in (prepared_pieces_dir / f\"Label Box {box}\").iterdir():\n",
    "        file_id = int(file_in_temp.stem.split(\"_\")[1])\n",
    "        new_id = file_id + (box) * 1000\n",
    "        shutil.copy(file_in_temp, prepared_dir_2ndlevel / \"Inputs\" / f\"RUN_{new_id}.pt\")\n",
    "\n",
    "        file_label = prepared_pieces_dir / f\"Label Box {box+1}\" / f\"RUN_{file_id}.pt\"\n",
    "        shutil.copy(file_label, prepared_dir_2ndlevel / \"Labels\" / f\"RUN_{new_id}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare 2nd level\n",
    "prepared_dir_2ndlevel = Path(paths[\"datasets_prepared_dir\"]) / f\"{dataset_name} cut_{number_boxes}pieces separate_boxes 2nd level gkt\"\n",
    "prepared_dir_2ndlevel.mkdir(parents=True, exist_ok=True)\n",
    "(prepared_dir_2ndlevel / \"Inputs\").mkdir(parents=True, exist_ok=True)\n",
    "(prepared_dir_2ndlevel / \"Labels\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "info = yaml.safe_load(open(prepared_dir_1stlevel / \"info.yaml\", \"r\"))\n",
    "info_g    = deepcopy(info[\"Inputs\"][\"Pressure Gradient [-]\"])\n",
    "info_k    = deepcopy(info[\"Inputs\"][\"Permeability X [m^2]\"])\n",
    "info[\"Inputs\"] = deepcopy(info[\"Labels\"])\n",
    "info[\"Inputs\"][\"Pressure Gradient [-]\"] = info_g\n",
    "info[\"Inputs\"][\"Permeability X [m^2]\"] = info_k\n",
    "info[\"Inputs\"][\"Temperature [C]\"][\"index\"] = 2\n",
    "# assert indices of inputs double\n",
    "idx_g = info[\"Inputs\"][\"Pressure Gradient [-]\"][\"index\"]\n",
    "idx_k = info[\"Inputs\"][\"Permeability X [m^2]\"][\"index\"]\n",
    "idx_t = info[\"Inputs\"][\"Temperature [C]\"][\"index\"]\n",
    "assert  idx_g != idx_k, \"indices of inputs double\"\n",
    "assert  idx_g != idx_t, \"indices of inputs double\"\n",
    "assert  idx_k != idx_t, \"indices of inputs double\"\n",
    "\n",
    "yaml.safe_dump(info, open(prepared_dir_2ndlevel / \"info.yaml\", \"w\"))\n",
    "\n",
    "for box in range(number_boxes-1):\n",
    "    for file_in_temp in (prepared_pieces_dir / f\"Label Box {box}\").iterdir():\n",
    "        file_id = int(file_in_temp.stem.split(\"_\")[1])\n",
    "        new_id = file_id + (box) * 1000\n",
    "        temp_in = torch.load(file_in_temp)\n",
    "        file_inputs = prepared_pieces_dir / f\"Inputs Box {box}\" / f\"RUN_{file_id}.pt\"\n",
    "        g_in = torch.load(file_inputs)[idx_g]\n",
    "        k_in = torch.load(file_inputs)[idx_k]\n",
    "        inputs = torch.zeros([3, *g_in.shape])\n",
    "        inputs[idx_g] = g_in\n",
    "        inputs[idx_k] = k_in\n",
    "        inputs[idx_t] = temp_in\n",
    "        \n",
    "        torch.save(inputs, prepared_dir_2ndlevel / \"Inputs\" / f\"RUN_{new_id}.pt\")\n",
    "\n",
    "        file_label = prepared_pieces_dir / f\"Label Box {box+1}\" / f\"RUN_{file_id}.pt\"\n",
    "        shutil.copy(file_label, prepared_dir_2ndlevel / \"Labels\" / f\"RUN_{new_id}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
